保险欺诈识别的研究方法和工具

1.建立回归分析模型查找关于欺诈问题的关键指标。 赋予相应的权重。

2.运用数据挖掘理论对保险欺诈进行研究。

3.人工智能技术阶段。

反欺诈和风控领域主要存在的几个问题: 
问题定义难、标注成本高、黑样本少或无，白样本存在噪声、异常原因不好查明、并且欺诈者手段在进化。

可以把关注点放在业务上而不是具体的模型(No Free Lunch)。难点在于如何挑选合适的方法去解决各环节所遇到的问题。

方法：

1.有大量标记的训练数据： 采用有监督学习，例如可解释性强的LR；黑箱组合模型：Bagging（Random Forest）、Boosting（XGBoost， GBM）、Stacking（实际环境中训练数据可能存在不少噪声，Random Forest相比Boosting方法对噪声具有更强的鲁棒性）。
2.有大量单类标记的数据，以及少量标记的另一类样本（若有）：半监督学习异常检测：比如通过多数类训练一个分布，用少数类确定阈值。PU Learning（ Learning from Positive and Unlabeled Examples）：例如one class sum 以及其他相关算法
3.有少量标记的训练数据：基于图的半监督学习， 例如贝叶斯网络、标签传播等。没有训练样本：人机共同学习
利用已有经验（若有）：从经验中提炼出强规则，通过规则进行识别。
提升经验：通过无监督方法（例如GMM、isolationForest）识别异常，人工分析欺诈性质的异常点，从而提升对欺诈的认知和经验。
反复进行1、2，直至“收敛”，再根据训练样本情况采用前面几种方案。

注意：无监督结果不可控，缺乏解释性，一般我们用于可以发现新的异常／模式，而不是直接建模。

1.可以用逻辑回归分析先行检验欺诈因子的有效性，精炼解释变量减少噪音干扰。

2.再使用BP神经网络识别。

各模型／方法比较
5.1 无监督聚类、异常检测:结果不可控，缺乏解释性，但是可以发现新的异常。比较流行的是:GMM、isolationforest、统计方法等。不过可以设计一个可解释强的图模型，使用图分割算法会有一定的收获。
5.2 有监督分类:在训练样本充足的情况下，有监督绝对为王。如果模型需要可解释性，LR是第一选择，不过需要做较多的特征工程才能达到一定的效果。黑箱模型的话，XGBoost、GBM、RF是比较流行的，还可以Stacking。
5.3 强规则/策略:可以快速上线，准确率高，但是对问题的召回率取决于规则制定者和问题难度。
5.4半监督: PU learning:虽然该类方法解决场景很match，但近两年好像没有新的研究，测的效果也一般。图论的相关传播算法：比如标签传播、基于贝叶斯网络等算法。

